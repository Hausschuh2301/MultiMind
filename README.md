# ðŸ§  MULTIMIND â€“ KI-Aggregator (lokal + API)

MULTIMIND kombiniert mehrere KI-Modelle (lokal und per API), um die besten Antworten zu generieren und diese zusammenzufassen.

---

## Features

- UnterstÃ¼tzung lokaler KI-Modelle (z.B. via Ollama)  
- API-Integration (OpenAI, Claude, u.a.)  
- Automatische Antwort-Kombination und Zusammenfassung  
- Konfigurierbar Ã¼ber YAML-Dateien  
- BenutzeroberflÃ¤che mit Streamlit  

---

## Projektstruktur

```
MULTIMIND/
â”œâ”€â”€ configs/             # Konfigurationsdateien (models.yaml)
â”œâ”€â”€ core/                # Kernlogik, Modell-Wrapper, Prompt-Router
â”œâ”€â”€ ui/                  # Streamlit-OberflÃ¤che
â”œâ”€â”€ .env.example         # Beispiel-Umgebungsvariablen
â”œâ”€â”€ requirements.txt     # Python-AbhÃ¤ngigkeiten
â””â”€â”€ README.md            # Dieses Dokument
```

---

## Installation

1. Repository klonen:

```bash
git clone https://github.com/Hausschuh2301/MultiMind.git
cd MultiMind
```

2. AbhÃ¤ngigkeiten installieren:

```bash
pip install -r requirements.txt
```

3. (Optional) Lokale KI-Modelle einrichten (z.B. Ollama):

```bash
bash scripts/setup_ollama.sh
```

---

## Nutzung

### Streamlit starten:

```bash
streamlit run ui/streamlit_app.py
```

### Modelle konfigurieren

Passe `configs/models.yaml` an, um API-Keys, Modellnamen und Aktivierung zu steuern.

---

## Lizenz

MIT Lizenz

---

## Autor

Hausschuh2301 â€“ 2025  
GitHub: [Hausschuh2301](https://github.com/Hausschuh2301)

---

## Support

Fragen oder Probleme? Issues Ã¶ffnen unter:  
https://github.com/Hausschuh2301/MultiMind/issues
